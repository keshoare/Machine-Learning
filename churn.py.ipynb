{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862bf7b-1832-4c96-844a-53cffc3368ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape (Rows, Columns): (7043, 21)\n",
      "\n",
      "Missing Values per Column:\n",
      " customerID          0\n",
      "gender              0\n",
      "SeniorCitizen       0\n",
      "Partner             0\n",
      "Dependents          0\n",
      "tenure              0\n",
      "PhoneService        0\n",
      "MultipleLines       0\n",
      "InternetService     0\n",
      "OnlineSecurity      0\n",
      "OnlineBackup        0\n",
      "DeviceProtection    0\n",
      "TechSupport         0\n",
      "StreamingTV         0\n",
      "StreamingMovies     0\n",
      "Contract            0\n",
      "PaperlessBilling    0\n",
      "PaymentMethod       0\n",
      "MonthlyCharges      0\n",
      "TotalCharges        0\n",
      "Churn               0\n",
      "dtype: int64\n",
      "\n",
      "Data Types before preprocessing:\n",
      " customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure                int64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges         object\n",
      "Churn                object\n",
      "dtype: object\n",
      "\n",
      "After Preprocessing:\n",
      "Dataset Shape: (7043, 31)\n",
      "\n",
      "Data Types after preprocessing:\n",
      " SeniorCitizen                              int64\n",
      "tenure                                     int64\n",
      "MonthlyCharges                           float64\n",
      "TotalCharges                             float64\n",
      "gender_Male                                 bool\n",
      "Partner_Yes                                 bool\n",
      "Dependents_Yes                              bool\n",
      "PhoneService_Yes                            bool\n",
      "MultipleLines_No phone service              bool\n",
      "MultipleLines_Yes                           bool\n",
      "InternetService_Fiber optic                 bool\n",
      "InternetService_No                          bool\n",
      "OnlineSecurity_No internet service          bool\n",
      "OnlineSecurity_Yes                          bool\n",
      "OnlineBackup_No internet service            bool\n",
      "OnlineBackup_Yes                            bool\n",
      "DeviceProtection_No internet service        bool\n",
      "DeviceProtection_Yes                        bool\n",
      "TechSupport_No internet service             bool\n",
      "TechSupport_Yes                             bool\n",
      "StreamingTV_No internet service             bool\n",
      "StreamingTV_Yes                             bool\n",
      "StreamingMovies_No internet service         bool\n",
      "StreamingMovies_Yes                         bool\n",
      "Contract_One year                           bool\n",
      "Contract_Two year                           bool\n",
      "PaperlessBilling_Yes                        bool\n",
      "PaymentMethod_Credit card (automatic)       bool\n",
      "PaymentMethod_Electronic check              bool\n",
      "PaymentMethod_Mailed check                  bool\n",
      "Churn_Yes                                   bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Task 1: Data Preparation )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "file_path = r\"C:\\MLProjects\\sklearn.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "print(\"Dataset Shape (Rows, Columns):\", df.shape)\n",
    "print(\"\\nMissing Values per Column:\\n\", df.isnull().sum())\n",
    "print(\"\\nData Types before preprocessing:\\n\", df.dtypes)\n",
    "\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors='coerce')\n",
    "df[\"TotalCharges\"] = df[\"TotalCharges\"].fillna(df[\"TotalCharges\"].mean()) \n",
    "df = df.drop(\"customerID\", axis=1)\n",
    "cat_cols = df.select_dtypes(include=\"object\").columns\n",
    "df = pd.get_dummies(df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "print(\"\\nAfter Preprocessing:\")\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nData Types after preprocessing:\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0809a66-f522-4a01-86d1-45310004d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = r\"C:\\MLProjects\\prepared_data.xlsx\"\n",
    "df.to_excel(output_path, index=False)\n",
    "print(f\"Preprocessed dataset saved at: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ab2051-222c-49bb-97d1-e1019174036e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (5634, 30) (5634,)\n",
      "Testing Set Shape: (1409, 30) (1409,)\n"
     ]
    }
   ],
   "source": [
    "#Task 2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "file_path = r\"C:\\MLProjects\\prepared_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "X = df.drop(\"Churn_Yes\", axis=1)   \n",
    "y = df[\"Churn_Yes\"]           \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Training Set Shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Set Shape:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb5a189-1108-49c2-a907-721c999b80e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Important Features:\n",
      "                           Feature  Importance\n",
      "3                     TotalCharges    0.192829\n",
      "1                           tenure    0.174197\n",
      "2                   MonthlyCharges    0.168527\n",
      "28  PaymentMethod_Electronic check    0.038726\n",
      "10     InternetService_Fiber optic    0.038579\n",
      "25               Contract_Two year    0.030102\n",
      "13              OnlineSecurity_Yes    0.028420\n",
      "4                      gender_Male    0.028348\n",
      "26            PaperlessBilling_Yes    0.025472\n",
      "5                      Partner_Yes    0.023348\n"
     ]
    }
   ],
   "source": [
    "# task 3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "file_path = r\"C:\\MLProjects\\prepared_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "X = df.drop(\"Churn_Yes\", axis=1)\n",
    "y = df[\"Churn_Yes\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "feature_importances = pd.DataFrame({\n",
    "    \"Feature\": X_train.columns,\n",
    "    \"Importance\": model.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(feature_importances.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87daeb4-62b7-47d6-a47f-6d4110f22e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KESHOARE\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.8041\n",
      "Decision Tree Accuracy: 0.7417\n",
      "Random Forest Accuracy: 0.7878\n",
      "Gradient Boosting Accuracy: 0.7970\n"
     ]
    }
   ],
   "source": [
    "#Task 4\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "file_path = r\"C:\\MLProjects\\prepared_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "X = df.drop(\"Churn_Yes\", axis=1)\n",
    "y = df[\"Churn_Yes\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86730e4-e8d8-49f4-9abe-d3397d42bc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Model Training\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "file_path = r\"C:\\MLProjects\\prepared_data.xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "X = df.drop(\"Churn_Yes\", axis=1)  \n",
    "y = df[\"Churn_Yes\"]               \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "model = LogisticRegression(max_iter=5000, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "print(\"Model training completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16d9e92-6149-44b3-8e50-f2ab7fb75c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Results:\n",
      "Accuracy      : 0.8070\n",
      "Precision     : 0.6584\n",
      "Recall        : 0.5668\n",
      "F1-Score      : 0.6092\n",
      "ROC-AUC Score : 0.8416\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.85      0.89      0.87      1035\n",
      "        True       0.66      0.57      0.61       374\n",
      "\n",
      "    accuracy                           0.81      1409\n",
      "   macro avg       0.75      0.73      0.74      1409\n",
      "weighted avg       0.80      0.81      0.80      1409\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 6: Model Evaluation\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "y_pred = model.predict(X_test_scaled) \n",
    "y_pred_prob = model.predict_proba(X_test_scaled)[:, 1]  \n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "\n",
    "print(\"Model Evaluation Results:\")\n",
    "print(f\"Accuracy      : {accuracy:.4f}\")\n",
    "print(f\"Precision     : {precision:.4f}\")\n",
    "print(f\"Recall        : {recall:.4f}\")\n",
    "print(f\"F1-Score      : {f1:.4f}\")\n",
    "print(f\"ROC-AUC Score : {roc_auc:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd59ba2-ec9d-41d1-ad09-568b7ce702db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78d3e27-f1ac-4fdc-96a2-f80dbd11e896",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
